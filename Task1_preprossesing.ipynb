{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "تنظیمات و import ها",
   "id": "af1bdc4eb7d2b4ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:40.079465261Z",
     "start_time": "2025-12-26T17:43:40.061957461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ========= PATHS =========\n",
    "ORDERS_PATH   = \"orders.csv\"\n",
    "PRIOR_PATH    = \"order_products__prior.csv\"\n",
    "TRAIN_PATH    = \"order_products__train.csv\"\n",
    "PRODUCTS_PATH = \"products.csv\"\n",
    "AISLES_PATH   = \"aisles.csv\"\n",
    "DEPTS_PATH    = \"departments.csv\"\n",
    "\n",
    "# ========= SUBSET SETTINGS =========\n",
    "TARGET_N_ORDERS = 15000\n",
    "MAX_USERS       = 20000   # سقف تعداد کاربر برای انتخاب سفارش‌ها (برای کنترل حجم)\n",
    "\n",
    "# ========= CHUNKING =========\n",
    "CHUNK_SIZE = 500_000  # اگر RAM کم بود: 200_000\n",
    "\n",
    "# ========= OUTPUT =========\n",
    "OUT_DIR = \"out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "CLEAN_ORDER_PRODUCTS_PATH = os.path.join(OUT_DIR, \"order_products_clean.csv\")\n",
    "CLEAN_ORDERS_PATH         = os.path.join(OUT_DIR, \"orders_clean.csv\")\n"
   ],
   "id": "73c15b243f6fa34a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "توابع کمکی (Chunk-friendly)",
   "id": "e468954f35aa4c4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:40.101840371Z",
     "start_time": "2025-12-26T17:43:40.081427179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def downcast_int(df: pd.DataFrame, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "def read_orders_subset(orders_path: str, target_n_orders: int, max_users: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) orders.csv رو با ستون‌های لازم می‌خونه\n",
    "    2) یک subset از کاربران انتخاب می‌کنه\n",
    "    3) از بین سفارش‌های آن کاربران، target_n_orders سفارش برمی‌داره\n",
    "    \"\"\"\n",
    "    usecols = [\"order_id\", \"user_id\", \"eval_set\", \"order_number\", \"order_dow\", \"order_hour_of_day\"]\n",
    "    orders = pd.read_csv(orders_path, usecols=usecols)\n",
    "\n",
    "    # حذف null ها (طبق صورت مسئله)\n",
    "    orders = orders.dropna()\n",
    "\n",
    "    # فقط سفارش‌هایی که واقعاً basket دارند (prior/train)\n",
    "    orders = orders[orders[\"eval_set\"].isin([\"prior\", \"train\"])].copy()\n",
    "\n",
    "    # کنترل اندازه با انتخاب subset از کاربران\n",
    "    rng = np.random.default_rng(42)\n",
    "    users = orders[\"user_id\"].unique()\n",
    "    if len(users) > max_users:\n",
    "        sampled_users = rng.choice(users, size=max_users, replace=False)\n",
    "        orders = orders[orders[\"user_id\"].isin(sampled_users)].copy()\n",
    "\n",
    "    # حالا از بین سفارش‌ها، target_n_orders برمی‌داریم\n",
    "    # (ترجیحاً سفارش‌های اخیرتر هر کاربر را نگه داریم)\n",
    "    orders = orders.sort_values([\"user_id\", \"order_number\"], ascending=[True, False])\n",
    "\n",
    "    if len(orders) > target_n_orders:\n",
    "        orders = orders.head(target_n_orders).copy()\n",
    "\n",
    "    orders = downcast_int(orders, [\"order_id\", \"user_id\", \"order_number\", \"order_dow\", \"order_hour_of_day\"])\n",
    "    return orders\n",
    "\n",
    "def load_order_products_filtered(path: str, keep_order_ids: set, chunk_size: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    order_products فایل‌های prior/train بسیار بزرگ‌اند.\n",
    "    این تابع با chunk می‌خواند و فقط order_id هایی که می‌خواهیم نگه می‌دارد.\n",
    "    \"\"\"\n",
    "    usecols = [\"order_id\", \"product_id\", \"add_to_cart_order\", \"reordered\"]\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunk_size):\n",
    "        chunk = chunk.dropna()\n",
    "        chunk = chunk[chunk[\"order_id\"].isin(keep_order_ids)].copy()\n",
    "        chunks.append(chunk)\n",
    "    if not chunks:\n",
    "        return pd.DataFrame(columns=usecols)\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    df = downcast_int(df, [\"order_id\", \"product_id\", \"add_to_cart_order\", \"reordered\"])\n",
    "    return df\n"
   ],
   "id": "ed9662ad3fd2eb58",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "اجرای Task 1: ساخت دیتاست تمیز",
   "id": "317ab9ed51a31840"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:49.144151635Z",
     "start_time": "2025-12-26T17:43:40.102601146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- STEP 1: orders subset ----\n",
    "orders_sub = read_orders_subset(ORDERS_PATH, TARGET_N_ORDERS, MAX_USERS)\n",
    "keep_order_ids = set(orders_sub[\"order_id\"].tolist())\n",
    "\n",
    "print(\"Selected orders:\", len(orders_sub))\n",
    "print(\"Selected users:\", orders_sub[\"user_id\"].nunique())\n",
    "print(\"Eval_set counts:\\n\", orders_sub[\"eval_set\"].value_counts())\n",
    "\n",
    "# ---- STEP 2: load order_products from BOTH prior + train (chunked) ----\n",
    "prior_sub = load_order_products_filtered(PRIOR_PATH, keep_order_ids, CHUNK_SIZE)\n",
    "train_sub = load_order_products_filtered(TRAIN_PATH, keep_order_ids, CHUNK_SIZE)\n",
    "\n",
    "print(\"prior_sub rows:\", len(prior_sub))\n",
    "print(\"train_sub rows:\", len(train_sub))\n",
    "\n",
    "order_products = pd.concat([prior_sub, train_sub], ignore_index=True)\n",
    "\n",
    "# آزاد کردن حافظه\n",
    "del prior_sub, train_sub\n",
    "gc.collect()\n",
    "\n",
    "print(\"order_products total rows:\", len(order_products))\n",
    "print(\"Unique orders in order_products:\", order_products[\"order_id\"].nunique())\n",
    "print(\"Unique products:\", order_products[\"product_id\"].nunique())\n"
   ],
   "id": "d46251e2d7e3931c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected orders: 15000\n",
      "Selected users: 939\n",
      "Eval_set counts:\n",
      " eval_set\n",
      "prior    14397\n",
      "train      603\n",
      "Name: count, dtype: int64\n",
      "prior_sub rows: 137327\n",
      "train_sub rows: 6096\n",
      "order_products total rows: 143423\n",
      "Unique orders in order_products: 15000\n",
      "Unique products: 14340\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cleaning دقیق برای Instacart",
   "id": "8fb10ca750c41e16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:49.225436269Z",
     "start_time": "2025-12-26T17:43:49.159305877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- STEP 3: Clean invalid rows ----\n",
    "\n",
    "# 1) حذف null ها (قبلاً هم انجام شد ولی اینجا دوباره امن)\n",
    "order_products = order_products.dropna()\n",
    "\n",
    "# 2) \"returned/negative quality\" در Instacart ستون quantity ندارد.\n",
    "# جایگزین منطقی: حذف رکوردهای خراب در add_to_cart_order (باید >=1 باشد)\n",
    "order_products = order_products[order_products[\"add_to_cart_order\"] >= 1].copy()\n",
    "\n",
    "# 3) حذف قیمت‌های <=0: در Instacart قیمت نداریم → این مرحله N/A است.\n",
    "# اما برای سازگاری، فرض می‌کنیم quantity=1 و داده منفی وجود ندارد.\n",
    "\n",
    "# 4) حذف تکراری‌ها داخل هر سفارش (اگر به هر دلیل محصول دوبار آمده باشد)\n",
    "order_products = order_products.drop_duplicates(subset=[\"order_id\", \"product_id\"]).copy()\n",
    "\n",
    "# 5) حذف سفارش‌هایی که فقط 1 کالا دارند (خیلی مهم برای ARM)\n",
    "order_sizes = order_products.groupby(\"order_id\")[\"product_id\"].nunique()\n",
    "valid_orders = order_sizes[order_sizes >= 2].index\n",
    "\n",
    "order_products = order_products[order_products[\"order_id\"].isin(valid_orders)].copy()\n",
    "orders_sub = orders_sub[orders_sub[\"order_id\"].isin(valid_orders)].copy()\n",
    "\n",
    "print(\"After removing 1-item orders:\")\n",
    "print(\"orders_sub:\", orders_sub.shape)\n",
    "print(\"order_products:\", order_products.shape)\n",
    "print(\"Min basket size:\", int(order_products.groupby(\"order_id\")[\"product_id\"].nunique().min()))\n"
   ],
   "id": "7e8254573ee91161",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing 1-item orders:\n",
      "orders_sub: (14132, 6)\n",
      "order_products: (142555, 4)\n",
      "Min basket size: 2\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "ذخیره خروجی برای Task 2",
   "id": "80c994234bca0706"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:49.350520992Z",
     "start_time": "2025-12-26T17:43:49.228456782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- STEP 4: Save cleaned outputs ----\n",
    "orders_sub.to_csv(CLEAN_ORDERS_PATH, index=False)\n",
    "order_products.to_csv(CLEAN_ORDER_PRODUCTS_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", CLEAN_ORDERS_PATH)\n",
    "print(\" -\", CLEAN_ORDER_PRODUCTS_PATH)\n"
   ],
   "id": "ea4fc9c5de9e61d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - out/orders_clean.csv\n",
      " - out/order_products_clean.csv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Self-Check نهایی",
   "id": "f4b2be06d89ba1e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T17:43:49.391975534Z",
     "start_time": "2025-12-26T17:43:49.351652086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== TASK 1 SELF-CHECK ===\")\n",
    "print(\"Clean orders:\", orders_sub[\"order_id\"].nunique())\n",
    "print(\"Clean order_products rows:\", len(order_products))\n",
    "print(\"Unique products:\", order_products[\"product_id\"].nunique())\n",
    "\n",
    "basket_sizes = order_products.groupby(\"order_id\")[\"product_id\"].nunique()\n",
    "print(\"Basket size min:\", int(basket_sizes.min()))\n",
    "print(\"Basket size mean:\", float(basket_sizes.mean()))\n",
    "print(\"Basket size max:\", int(basket_sizes.max()))\n"
   ],
   "id": "79c76915d5b6843a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TASK 1 SELF-CHECK ===\n",
      "Clean orders: 14132\n",
      "Clean order_products rows: 142555\n",
      "Unique products: 14304\n",
      "Basket size min: 2\n",
      "Basket size mean: 10.087390319841495\n",
      "Basket size max: 74\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
